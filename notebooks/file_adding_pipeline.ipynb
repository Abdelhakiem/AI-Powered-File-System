{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers  import BlipProcessor, BlipForConditionalGeneration\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import faiss\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers import BlipProcessor, BlipForImageTextRetrieval, BlipForConditionalGeneration\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_TXT_PATH = \"../models/img_to_text/\"\n",
    "SUMMARIZER_PATH = \"../models/summarizer/\"\n",
    "# Paths where you previously saved the BLIP models & processors:\n",
    "LOCAL_CAPTION_DIR = \"../models/img_caption\"\n",
    "LOCAL_RETRIEVAL_DIR    = \"../models/embedding\"\n",
    "\n",
    "FILE_STORING_PATH ='../files_DB'\n",
    "FILE_SYSTEM_PATH  = '../File_System_Simulation'\n",
    "VECTOR_DB_PATH = '../vectorDB'\n",
    "# Choose device (GPU if available):\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # summarizer:\n",
    "# summary_tokenizer = AutoTokenizer.from_pretrained(SUMMARIZER_PATH)\n",
    "# summary_model = AutoModelForSeq2SeqLM.from_pretrained(SUMMARIZER_PATH)\n",
    "# summarizer = pipeline(\"summarization\", model=summary_model, tokenizer=summary_tokenizer)\n",
    "\n",
    "# # embedding model:\n",
    "# emb_processor = CLIPProcessor.from_pretrained(LOCAL_RETRIEVAL_DIR)\n",
    "# emb_model     = CLIPModel.from_pretrained(LOCAL_RETRIEVAL_DIR).to(device)\n",
    "    \n",
    "\n",
    "# def text_to_vector(text: str, emb_model, emb_processor) -> np.ndarray:\n",
    "#     inputs = emb_processor(text=text, return_tensors=\"pt\", padding=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         text_features = emb_model.get_text_features(**inputs)\n",
    "#     # Normalize to unit vector (L2 norm)\n",
    "#     text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "#     return text_features.cpu().numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def text_to_vector(text: str, emb_model, emb_processor) -> np.ndarray:\n",
    "#     inputs = emb_processor(text=text, return_tensors=\"pt\", padding=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         text_features = emb_model.get_text_features(**inputs)\n",
    "#     # Normalize to unit vector (L2 norm)\n",
    "#     text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "#     return text_features.cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "# def summarize_text_file(summarizer, text):\n",
    "#     return summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_models():\n",
    "\n",
    "    # summarizer:\n",
    "    summary_tokenizer = AutoTokenizer.from_pretrained(SUMMARIZER_PATH)\n",
    "    summary_model = AutoModelForSeq2SeqLM.from_pretrained(SUMMARIZER_PATH)\n",
    "    summarizer = pipeline(\"summarization\", model=summary_model, tokenizer=summary_tokenizer)\n",
    "\n",
    "    # image captioning\n",
    "    caption_processor = BlipProcessor.from_pretrained(LOCAL_CAPTION_DIR)\n",
    "    caption_model     = BlipForConditionalGeneration.from_pretrained(LOCAL_CAPTION_DIR).to(device)\n",
    "\n",
    "    # embedding model:\n",
    "    emb_processor = CLIPProcessor.from_pretrained(LOCAL_RETRIEVAL_DIR)\n",
    "    emb_model     = CLIPModel.from_pretrained(LOCAL_RETRIEVAL_DIR).to(device)\n",
    "    \n",
    "    return summarizer, caption_processor, caption_model, emb_processor, emb_model\n",
    "\n",
    "def text_to_vector(text: str, emb_model, emb_processor) -> np.ndarray:\n",
    "    inputs = emb_processor(text=text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = emb_model.get_text_features(**inputs)\n",
    "    # Normalize to unit vector (L2 norm)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features.cpu().numpy().squeeze()\n",
    "\n",
    "# 2. Image to normalized vector (using CLIP)\n",
    "def image_to_vector(image: Image.Image, emb_model, emb_processor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert image to normalized L2 vector using CLIP\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        \n",
    "    Returns:\n",
    "        Normalized embedding vector (numpy array)\n",
    "    \"\"\"\n",
    "    inputs = emb_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = emb_model.get_image_features(**inputs)\n",
    "    # Normalize to unit vector (L2 norm)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    return image_features.cpu().numpy().squeeze()\n",
    "\n",
    "# 3. Image to caption (using BLIP)\n",
    "def image_to_caption(image: Image.Image,caption_processor, caption_model , max_length: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    Generate caption from image using BLIP\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        max_length: Maximum caption length (default 30)\n",
    "        \n",
    "    Returns:\n",
    "        Generated caption string\n",
    "    \"\"\"\n",
    "    inputs = caption_processor(image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = caption_model.generate(**inputs, max_length=max_length)\n",
    "    caption = caption_processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "\n",
    "def summarize_text_file(summarizer, text):\n",
    "    return summarizer(text, max_length=50, min_length=20, do_sample=False)[0]['summary_text']\n",
    "\n",
    "\n",
    "def check_file_type(file_path) -> str:\n",
    "    file_path = Path(file_path)\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    \n",
    "    if mime_type:\n",
    "        if mime_type.startswith(\"image/\"):\n",
    "            return \"image\"\n",
    "        elif mime_type.startswith(\"text/\"):\n",
    "            return \"text\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def generate_file_id(file_path) -> str:\n",
    "    file_path = Path(file_path)\n",
    "    path_hash = hashlib.md5(str(file_path.resolve()).encode()).hexdigest()[:8]\n",
    "    return f\"{file_path.stem}_{path_hash}\"\n",
    "\n",
    "\n",
    "\n",
    "def store_file(file_id: str, original_file_path: str, file_type: str):\n",
    "    # Create storage directory if it doesn't exist\n",
    "    os.makedirs(FILE_STORING_PATH, exist_ok=True)\n",
    "    \n",
    "    # Get the original file extension\n",
    "    original_path = Path(original_file_path)\n",
    "    file_extension = original_path.suffix.lower()\n",
    "    \n",
    "    # Handle files without extensions\n",
    "    if not file_extension:\n",
    "        if file_type == 'image':\n",
    "            file_extension = '.jpg'  # Default image format\n",
    "        else:\n",
    "            file_extension = '.txt'  # Default text format\n",
    "    \n",
    "    # Create storage path with file_id + original extension\n",
    "    storage_path = os.path.join(FILE_STORING_PATH, f\"{file_id}{file_extension}\")\n",
    "    \n",
    "    # Copy the file to storage\n",
    "    try:\n",
    "        if file_type == 'image':\n",
    "            # For images, we use the processed version to maintain RGB format\n",
    "            with Image.open(original_file_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img.save(storage_path)\n",
    "            print(f\"Stored image: {storage_path}\")\n",
    "        else:\n",
    "            # For text files, copy the original content\n",
    "            shutil.copy2(original_file_path, storage_path)\n",
    "            print(f\"Stored text: {storage_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error storing file {original_file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return storage_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "INDEX_FILE = os.path.join(VECTOR_DB_PATH, \"file_index.faiss\")\n",
    "METADATA_FILE = os.path.join(VECTOR_DB_PATH, \"index_metadata.json\")\n",
    "\n",
    "# Initialize global variables\n",
    "index = None\n",
    "metadata_list = []\n",
    "\n",
    "def load_or_create_vector_db():\n",
    "    global index, metadata_list\n",
    "    os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
    "    # Check if database exists\n",
    "    if os.path.exists(INDEX_FILE) and os.path.exists(METADATA_FILE):\n",
    "        print(\"Loading existing vector database...\")\n",
    "        try:\n",
    "            # Load FAISS index\n",
    "            index = faiss.read_index(INDEX_FILE)\n",
    "            \n",
    "            # Load metadata\n",
    "            with open(METADATA_FILE, 'r') as f:\n",
    "                metadata_list = json.load(f)\n",
    "                \n",
    "            print(f\"Loaded vector DB with {index.ntotal} entries\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector DB: {e}\")\n",
    "            create_new_vector_db()\n",
    "    else:\n",
    "        print(\"Creating new vector database...\")\n",
    "        create_new_vector_db()\n",
    "        \n",
    "    return index, metadata_list\n",
    "\n",
    "def create_new_vector_db():\n",
    "    \"\"\"Create a new empty vector database\"\"\"\n",
    "    global index, metadata_list\n",
    "    dimension = 512  # CLIP embedding dimension\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    metadata_list = []\n",
    "    save_vector_db()\n",
    "    print(f\"Created new vector DB with dimension {dimension}\")\n",
    "\n",
    "def save_vector_db():\n",
    "    \"\"\"Save the vector database to disk\"\"\"\n",
    "    try:\n",
    "        # Save FAISS index\n",
    "        faiss.write_index(index, INDEX_FILE)\n",
    "        \n",
    "        # Save metadata\n",
    "        with open(METADATA_FILE, 'w') as f:\n",
    "            json.dump(metadata_list, f, indent=2)\n",
    "            \n",
    "        print(f\"Saved vector DB with {index.ntotal} entries\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving vector DB: {e}\")\n",
    "\n",
    "def store_embedding(embedding: np.ndarray, meta_data: dict):\n",
    "    \"\"\"\n",
    "    Store embedding and metadata in vector database\n",
    "    \n",
    "    Args:\n",
    "        embedding: Embedding vector (1D numpy array)\n",
    "        meta_data: Metadata dictionary\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    # Ensure embedding is in correct format\n",
    "    if len(embedding.shape) == 1:\n",
    "        embedding = embedding.reshape(1, -1)\n",
    "    \n",
    "    # Add to index\n",
    "    index.add(embedding.astype('float32'))\n",
    "    \n",
    "    # Add to metadata\n",
    "    metadata_list.append(meta_data)\n",
    "    \n",
    "    # Save to disk\n",
    "    save_vector_db()\n",
    "    \n",
    "    print(f\"Stored embedding for: {meta_data['file_name']}\")\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Update the store_Vdb function\n",
    "def store_Vdb(embedding: np.ndarray, meta_data: dict):\n",
    "    \"\"\"Store in vector database (actual implementation)\"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    # Load DB if not already loaded\n",
    "    if index is None:\n",
    "        index, metadata_list = load_or_create_vector_db()\n",
    "    \n",
    "    # Store the embedding\n",
    "    store_embedding(embedding, meta_data)\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def retrieve_all_embeddings():\n",
    "    \"\"\"\n",
    "    Retrieve all stored embeddings and metadata\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (embeddings, metadata_list)\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    if index.ntotal == 0:\n",
    "        return np.array([]), []\n",
    "    \n",
    "    # Retrieve all embeddings\n",
    "    all_embeddings = index.reconstruct_n(0, index.ntotal)\n",
    "    \n",
    "    return all_embeddings, metadata_list\n",
    "\n",
    "def search_similar(query_embedding: np.ndarray, k: int = 5):\n",
    "    \"\"\"\n",
    "    Search for similar vectors in the database\n",
    "    \n",
    "    Args:\n",
    "        query_embedding: Embedding vector to compare against\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Metadata of top k matches\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    if index.ntotal == 0:\n",
    "        return []\n",
    "    \n",
    "    # Prepare query vector\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding.reshape(1, -1)\n",
    "    \n",
    "    # Perform search\n",
    "    distances, indices = index.search(query_embedding.astype('float32'), k)\n",
    "    \n",
    "    # Get metadata for results\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        if i >= 0:  # FAISS returns -1 for invalid indices\n",
    "            results.append(metadata_list[i])\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# New function for searching files\n",
    "def search_files(query: str, k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search files based on text query\n",
    "    \n",
    "    Args:\n",
    "        query: Text query to search for\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of metadata dictionaries for matching files\n",
    "    \"\"\"\n",
    "    # Load models and DB\n",
    "    _, _, _, emb_processor, emb_model = load_models()\n",
    "    if index is None:\n",
    "        index, metadata_list = load_or_create_vector_db()\n",
    "    \n",
    "    # Convert query to embedding\n",
    "    query_embedding = text_to_vector(query, emb_model, emb_processor)\n",
    "    \n",
    "    # Search vector DB\n",
    "    results = search_similar(query_embedding, k)\n",
    "    \n",
    "    # Format results\n",
    "    for result in results:\n",
    "        result['stored_file'] = os.path.join(\n",
    "            FILE_STORING_PATH, \n",
    "            f\"{result['file_id']}{Path(result['file_path']).suffix}\"\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector database...\n",
      "Loaded vector DB with 4 entries\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add_file_pipeline( file_path):\n",
    "    load_or_create_vector_db()\n",
    "    loading_file_path = os.path.join(FILE_SYSTEM_PATH, file_path)\n",
    "    # 0. Load models: \n",
    "    summarizer, caption_processor, caption_model, emb_processor, emb_model = load_models()\n",
    "    \n",
    "    # 1. check file type: image, text, unknown\n",
    "    file_type = check_file_type(file_path)\n",
    "    file_name = Path(file_path).name\n",
    "    file_id = generate_file_id(file_path)\n",
    "\n",
    "    # Process based on file type\n",
    "    if file_type == 'image':\n",
    "        try:\n",
    "            with Image.open(loading_file_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                content = image_to_caption(img, caption_processor, caption_model)\n",
    "                emb_vec = image_to_vector(img, emb_model, emb_processor)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {loading_file_path}: {e}\")\n",
    "            return None\n",
    "            \n",
    "    elif file_type == 'text':\n",
    "        try:\n",
    "            with open(loading_file_path, 'r', encoding='utf-8') as f:\n",
    "                full_text = f.read()\n",
    "                content = summarize_text_file(summarizer, full_text)\n",
    "                emb_vec = text_to_vector(content, emb_model, emb_processor)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text file {file_path}: {e}\")\n",
    "            return None\n",
    "            \n",
    "    else:\n",
    "        print(f\"Skipping unsupported file type: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "    storage_path = store_file(file_id, original_file_path =loading_file_path , file_type =file_type)\n",
    "\n",
    "    metadata = {\n",
    "        'file_id': file_id,\n",
    "        'file_name': file_name,\n",
    "        'file_path': str(Path(file_path).resolve()),\n",
    "        'file_type': file_type,\n",
    "        'content': content,\n",
    "        'storage_path' : storage_path\n",
    "    }\n",
    "    store_Vdb(emb_vec, metadata)\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file:  swimming.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored text: ../files_DB/swimming_7d550e69.txt\n",
      "Saved vector DB with 6 entries\n",
      "Stored embedding for: swimming.txt\n",
      "Processing file:  dir1/football.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored image: ../files_DB/football_3495d2eb.png\n",
      "Saved vector DB with 7 entries\n",
      "Stored embedding for: football.png\n",
      "Processing file:  dir1/statistical_testing.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored text: ../files_DB/statistical_testing_f17bd31b.txt\n",
      "Saved vector DB with 8 entries\n",
      "Stored embedding for: statistical_testing.txt\n",
      "Processing file:  dir1/football.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored text: ../files_DB/football_121b4c9f.txt\n",
      "Saved vector DB with 9 entries\n",
      "Stored embedding for: football.txt\n",
      "Processing file:  dir2/sea.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored image: ../files_DB/sea_13bd8c9b.png\n",
      "Saved vector DB with 10 entries\n",
      "Stored embedding for: sea.png\n",
      "Processing file:  dir2/math.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored text: ../files_DB/math_621e6b1f.txt\n",
      "Saved vector DB with 11 entries\n",
      "Stored embedding for: math.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files_recursive(root_path):\n",
    "    \"\"\"\n",
    "    Return a list of all files under `root_path`, with each path given\n",
    "    relative to `root_path` itself.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path : str\n",
    "        The directory from which to start the recursive search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        A list of file paths (as strings), each relative to `root_path`.\n",
    "        e.g. if root_path = \"/home/user/project\", and there is a file\n",
    "        \"/home/user/project/src/main.py\", this list will contain \"src/main.py\".\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # os.walk traverses dirpath, dirnames, filenames in a top-down manner\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        for filename in filenames:\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            # Compute the path relative to the root_path\n",
    "            rel_path = os.path.relpath(full_path, start=root_path)\n",
    "            # Normalize to use forward slashes even on Windows (optional)\n",
    "            result.append(rel_path)\n",
    "    return result\n",
    "\n",
    "def process_all_files(root_path):\n",
    "    rel_file_paths = list_files_recursive(root_path)\n",
    "    for rel_file_path in rel_file_paths:\n",
    "        print('Processing file: ', rel_file_path)\n",
    "        add_file_pipeline( rel_file_path)\n",
    "\n",
    "\n",
    "\n",
    "process_all_files('../File_System_Simulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "\n",
    "# Get the directory of the current script\n",
    "LOCAL_RETRIEVAL_DIR =   \"../models/embedding\"\n",
    "VECTOR_DB_PATH =   \"../vectorDB\"\n",
    "INDEX_FILE =  \"file_index.faiss\"\n",
    "METADATA_FILE = \"index_metadata.json\"\n",
    "\n",
    "\n",
    "index = None\n",
    "metadata_list = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def load_models():\n",
    "    emb_processor = CLIPProcessor.from_pretrained(LOCAL_RETRIEVAL_DIR)\n",
    "    emb_model     = CLIPModel.from_pretrained(LOCAL_RETRIEVAL_DIR).to(device)\n",
    "    return emb_processor, emb_model\n",
    "\n",
    "def text_to_vector(text: str, emb_model, emb_processor) -> np.ndarray:\n",
    "    inputs = emb_processor(text=text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = emb_model.get_text_features(**inputs)\n",
    "    # Normalize to unit vector (L2 norm)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features.cpu().numpy().squeeze()\n",
    "\n",
    "def load_or_create_vector_db():\n",
    "    global index, metadata_list\n",
    "    os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
    "    # Check if database exists\n",
    "    if os.path.exists(INDEX_FILE) and os.path.exists(METADATA_FILE):\n",
    "        print(\"Loading existing vector database...\")\n",
    "        try:\n",
    "            # Load FAISS index\n",
    "            index = faiss.read_index(INDEX_FILE)\n",
    "            \n",
    "            # Load metadata\n",
    "            with open(METADATA_FILE, 'r') as f:\n",
    "                metadata_list = json.load(f)\n",
    "                \n",
    "            print(f\"Loaded vector DB with {index.ntotal} entries\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector DB: {e}\")\n",
    "            create_new_vector_db()\n",
    "    else:\n",
    "        print(\"Creating new vector database...\")\n",
    "        create_new_vector_db()\n",
    "        \n",
    "    return index, metadata_list\n",
    "def create_new_vector_db():\n",
    "    \"\"\"Create a new empty vector database\"\"\"\n",
    "    global index, metadata_list\n",
    "    dimension = 512  # CLIP embedding dimension\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    metadata_list = []\n",
    "    save_vector_db()\n",
    "    print(f\"Created new vector DB with dimension {dimension}\")\n",
    "\n",
    "def save_vector_db():\n",
    "    \"\"\"Save the vector database to disk\"\"\"\n",
    "    try:\n",
    "        # Save FAISS index\n",
    "        faiss.write_index(index, INDEX_FILE)\n",
    "        \n",
    "        # Save metadata\n",
    "        with open(METADATA_FILE, 'w') as f:\n",
    "            json.dump(metadata_list, f, indent=2)\n",
    "            \n",
    "        print(f\"Saved vector DB with {index.ntotal} entries\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving vector DB: {e}\")\n",
    "\n",
    "def search_similar(query_embedding: np.ndarray, k: int = 5):\n",
    "    \"\"\"\n",
    "    Search for similar vectors in the database\n",
    "    \n",
    "    Args:\n",
    "        query_embedding: Embedding vector to compare against\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Metadata of top k matches\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    if index.ntotal == 0:\n",
    "        return []\n",
    "    \n",
    "    # Prepare query vector\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding.reshape(1, -1)\n",
    "    \n",
    "    # Perform search\n",
    "    distances, indices = index.search(query_embedding.astype('float32'), k)\n",
    "    \n",
    "    # Get metadata for results\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        if i >= 0:  # FAISS returns -1 for invalid indices\n",
    "            results.append(metadata_list[i]['file_path'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def semantic_search_engine(search_query: str):\n",
    "    load_or_create_vector_db()\n",
    "    emb_processor, emb_model = load_models()\n",
    "    search_emb = text_to_vector(search_query, emb_model, emb_processor)\n",
    "    relevant_files_paths = search_similar(search_emb)\n",
    "    return relevant_files_paths\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector database...\n",
      "Loaded vector DB with 0 entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query = \"sea with blue sky\"\n",
    "semantic_search_engine(search_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "def list_files_recursive(directory_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Recursively list all file paths in a directory and its subdirectories\n",
    "    \n",
    "    Args:\n",
    "        directory_path: Path to the root directory to scan\n",
    "        \n",
    "    Returns:\n",
    "        List of absolute paths to all files found\n",
    "    \"\"\"\n",
    "    # Convert to absolute path and ensure it exists\n",
    "    abs_path = Path(directory_path).resolve()\n",
    "    if not abs_path.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {abs_path}\")\n",
    "    if not abs_path.is_dir():\n",
    "        raise NotADirectoryError(f\"Path is not a directory: {abs_path}\")\n",
    "    \n",
    "    file_paths = []\n",
    "    \n",
    "    # Walk through directory tree\n",
    "    for root, _, files in os.walk(abs_path):\n",
    "        for filename in files:\n",
    "            # Create full path to file\n",
    "            file_path = Path(root) / filename\n",
    "            # Add to results\n",
    "            file_paths.append(str(file_path))\n",
    "    \n",
    "    return file_paths\n",
    "\n",
    "\n",
    "\n",
    "files = list_files_recursive('../File_System_Simulation/')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
