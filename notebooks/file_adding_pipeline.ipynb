{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers  import BlipProcessor, BlipForConditionalGeneration\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import faiss\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers import BlipProcessor, BlipForImageTextRetrieval, BlipForConditionalGeneration\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_TXT_PATH = \"../models/img_to_text/\"\n",
    "SUMMARIZER_PATH = \"../models/summarizer/\"\n",
    "# Paths where you previously saved the BLIP models & processors:\n",
    "LOCAL_CAPTION_DIR = \"../models/img_caption\"\n",
    "LOCAL_RETRIEVAL_DIR    = \"../models/embedding\"\n",
    "\n",
    "FILE_STORING_PATH ='../files_DB'\n",
    "FILE_SYSTEM_PATH  = '../File_System_Simulation'\n",
    "VECTOR_DB_PATH = '../vectorDB'\n",
    "# Choose device (GPU if available):\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_models():\n",
    "\n",
    "    # summarizer:\n",
    "    summary_tokenizer = AutoTokenizer.from_pretrained(SUMMARIZER_PATH)\n",
    "    summary_model = AutoModelForSeq2SeqLM.from_pretrained(SUMMARIZER_PATH)\n",
    "    summarizer = pipeline(\"summarization\", model=summary_model, tokenizer=summary_tokenizer)\n",
    "\n",
    "    # image captioning\n",
    "    caption_processor = BlipProcessor.from_pretrained(LOCAL_CAPTION_DIR)\n",
    "    caption_model     = BlipForConditionalGeneration.from_pretrained(LOCAL_CAPTION_DIR).to(device)\n",
    "\n",
    "    # embedding model:\n",
    "    emb_processor = CLIPProcessor.from_pretrained(LOCAL_RETRIEVAL_DIR)\n",
    "    emb_model     = CLIPModel.from_pretrained(LOCAL_RETRIEVAL_DIR).to(device)\n",
    "    \n",
    "    return summarizer, caption_processor, caption_model, emb_processor, emb_model\n",
    "\n",
    "def text_to_vector(text: str, emb_model, emb_processor) -> np.ndarray:\n",
    "    inputs = emb_processor(text=text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = emb_model.get_text_features(**inputs)\n",
    "    # Normalize to unit vector (L2 norm)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features.cpu().numpy().squeeze()\n",
    "\n",
    "# 2. Image to normalized vector (using CLIP)\n",
    "def image_to_vector(image: Image.Image, emb_model, emb_processor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert image to normalized L2 vector using CLIP\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        \n",
    "    Returns:\n",
    "        Normalized embedding vector (numpy array)\n",
    "    \"\"\"\n",
    "    inputs = emb_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = emb_model.get_image_features(**inputs)\n",
    "    # Normalize to unit vector (L2 norm)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    return image_features.cpu().numpy().squeeze()\n",
    "\n",
    "# 3. Image to caption (using BLIP)\n",
    "def image_to_caption(image: Image.Image,caption_processor, caption_model , max_length: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    Generate caption from image using BLIP\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        max_length: Maximum caption length (default 30)\n",
    "        \n",
    "    Returns:\n",
    "        Generated caption string\n",
    "    \"\"\"\n",
    "    inputs = caption_processor(image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = caption_model.generate(**inputs, max_length=max_length)\n",
    "    caption = caption_processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "\n",
    "def summarize_text_file(summarizer, text):\n",
    "    return summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
    "\n",
    "\n",
    "def check_file_type(file_path) -> str:\n",
    "    file_path = Path(file_path)\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    \n",
    "    if mime_type:\n",
    "        if mime_type.startswith(\"image/\"):\n",
    "            return \"image\"\n",
    "        elif mime_type.startswith(\"text/\"):\n",
    "            return \"text\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def generate_file_id(file_path) -> str:\n",
    "    file_path = Path(file_path)\n",
    "    path_hash = hashlib.md5(str(file_path.resolve()).encode()).hexdigest()[:8]\n",
    "    return f\"{file_path.stem}_{path_hash}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sea.png'\n",
    "loading_file_path = os.path.join(FILE_SYSTEM_PATH, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'image'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'sea.png'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'sea_54380609'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. Load models: \n",
    "summarizer, caption_processor, caption_model, emb_processor, emb_model = load_models()\n",
    "\n",
    "# 1. check file type: image, text, unknown\n",
    "file_type = check_file_type(file_path)\n",
    "file_name = Path(file_path).name\n",
    "file_id = generate_file_id(file_path)\n",
    "\n",
    "display(\n",
    "    file_type , \n",
    "    file_name,\n",
    "    file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a beach with waves and clouds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.26300165e-02,  1.49946837e-02, -1.45996800e-02, -6.55191718e-03,\n",
       "        7.53544318e-03, -1.76167302e-02,  1.60724148e-02,  4.06984650e-02,\n",
       "        4.85199206e-02,  2.16006376e-02,  2.94376276e-02, -2.13964339e-02,\n",
       "        6.21252926e-03, -2.52609863e-03,  2.10647658e-02, -2.10154112e-02,\n",
       "       -2.90923771e-02,  4.47862335e-02,  6.62008002e-02, -2.54076961e-02,\n",
       "       -5.94157726e-02,  2.49163583e-02,  2.05598306e-02, -2.36844621e-03,\n",
       "       -1.03093972e-02,  4.66534793e-02,  2.48438418e-02, -1.56605430e-02,\n",
       "       -1.07810348e-02,  1.11055642e-03, -2.72567361e-03,  2.16117781e-02,\n",
       "       -2.23331414e-02, -4.21095220e-03, -7.18788709e-03,  2.73612514e-03,\n",
       "       -2.09477171e-02,  1.20199919e-02,  4.29112557e-03,  1.14516146e-01,\n",
       "        1.94068849e-02,  2.56641693e-02, -7.78234156e-04, -1.19918799e-02,\n",
       "        1.12227974e-02, -1.12327628e-01, -3.03490795e-02,  1.58793479e-02,\n",
       "        2.07514153e-03, -8.20735120e-04, -1.13206096e-02,  2.85740644e-02,\n",
       "        3.02011315e-02, -4.89942133e-02, -4.17597517e-02,  3.80397849e-02,\n",
       "       -1.29785473e-02, -6.82390702e-04,  8.69771745e-03,  9.53483954e-03,\n",
       "       -3.32932398e-02, -1.72839798e-02, -9.69892554e-03, -1.71971824e-02,\n",
       "        3.66890756e-03, -1.41292410e-02, -9.05778725e-04,  1.24794103e-01,\n",
       "       -8.19213875e-03,  3.12652029e-02, -4.22005169e-02,  2.62825261e-03,\n",
       "       -3.79807800e-02, -3.40784825e-02, -5.00520598e-03, -1.19481999e-02,\n",
       "        1.59183815e-02, -3.64186615e-02, -5.18818898e-03, -5.71087524e-02,\n",
       "        1.70525722e-03, -2.40842141e-02,  2.36959588e-02, -3.86560075e-02,\n",
       "        2.58619487e-02,  1.56764258e-02, -4.00052629e-02, -7.26806466e-03,\n",
       "       -4.23543341e-02, -2.62515284e-02,  6.38253149e-03, -3.90037335e-02,\n",
       "       -6.96573794e-01,  3.15981098e-02, -1.92753095e-02,  4.70082387e-02,\n",
       "       -2.45454647e-02,  1.08294962e-02,  2.41618231e-02, -1.89316079e-01,\n",
       "       -1.82266776e-02, -1.64262727e-02, -5.86391166e-02,  8.46571568e-03,\n",
       "        5.47594316e-02, -1.10901985e-03, -9.33308341e-03,  1.94235854e-02,\n",
       "       -5.63421380e-03,  5.86985331e-03, -9.95954126e-03, -3.78114707e-03,\n",
       "        2.80588809e-02, -1.53181348e-02,  2.60252990e-02, -1.31697031e-02,\n",
       "       -1.98262297e-02,  3.91217042e-03, -1.35171637e-02, -3.76312225e-03,\n",
       "        2.39845458e-03,  5.71883954e-02,  3.46240550e-02, -4.26706001e-02,\n",
       "       -1.63418557e-02,  2.91180350e-02, -9.36234277e-03, -1.78254228e-02,\n",
       "        1.73469819e-02,  9.13681649e-03, -5.11560310e-03, -9.75751970e-03,\n",
       "       -2.42524147e-02,  7.80230984e-02,  2.23835334e-02,  2.37970222e-02,\n",
       "        3.25695127e-02,  4.19767573e-03, -1.89526975e-02, -2.71211453e-02,\n",
       "       -2.11790651e-02, -1.87232308e-02,  2.19038222e-03, -1.37833273e-02,\n",
       "        2.01886389e-02, -1.15147298e-02, -8.63735843e-03,  5.02959965e-03,\n",
       "       -2.17139255e-02,  1.35768550e-02,  2.67926827e-02,  9.95620806e-03,\n",
       "        5.67908734e-02,  1.56856924e-02, -1.44915394e-02, -2.58556046e-02,\n",
       "       -7.46086566e-03, -1.55843915e-02,  1.45264976e-02,  3.25999297e-02,\n",
       "       -1.83332600e-02, -1.51469670e-02,  3.36445053e-03,  9.76253394e-03,\n",
       "        2.46549211e-02,  9.21554491e-03,  1.13950325e-02,  4.47894149e-02,\n",
       "       -2.17801072e-02,  1.01083191e-02, -7.99354166e-03,  2.56574107e-03,\n",
       "       -5.17497677e-03,  4.04738169e-03,  6.63952809e-03,  3.85020673e-02,\n",
       "       -5.16187698e-02,  1.13931810e-02, -7.09041208e-02,  2.18496453e-02,\n",
       "        6.20148107e-02,  6.30212063e-03, -1.27438810e-02, -1.79385711e-02,\n",
       "        9.27514117e-03,  1.49011901e-02,  8.10940925e-04, -3.45723741e-02,\n",
       "       -1.91115716e-03, -1.53889218e-02, -2.80764587e-02, -2.56336126e-02,\n",
       "       -2.84289569e-02, -9.73309763e-03,  2.49147806e-02,  9.69621979e-05,\n",
       "        1.74325798e-02,  7.84281548e-03, -3.73413414e-03, -6.11623190e-03,\n",
       "        1.23352213e-02,  3.96645803e-04, -9.13937297e-03,  2.05682367e-02,\n",
       "        1.24945492e-02, -2.34233513e-02, -1.67253818e-02, -5.61934803e-03,\n",
       "        2.38345079e-02,  2.68275961e-02,  2.86267791e-03,  4.38493714e-02,\n",
       "        3.62219010e-03,  1.29619613e-02, -5.24637513e-02,  1.19181890e-02,\n",
       "        3.25450636e-02,  3.57250571e-02,  2.29198169e-02,  9.00316238e-03,\n",
       "        2.22080648e-02, -2.67169327e-02,  8.56996328e-03, -1.85744874e-02,\n",
       "        6.43833578e-02,  8.37252755e-03, -5.81495417e-03, -4.20325510e-02,\n",
       "        5.45182778e-03,  1.56445801e-02, -1.25669288e-02,  1.67664867e-02,\n",
       "       -5.53598534e-03,  9.09442455e-03,  1.97402164e-02, -9.18473080e-02,\n",
       "        7.81766418e-03, -1.56791545e-02,  9.49913729e-03, -1.46352723e-02,\n",
       "       -2.98213549e-02,  2.23526396e-02,  3.18301059e-02,  9.76006221e-03,\n",
       "        1.33200968e-02, -1.35235414e-02, -7.33283674e-03,  2.78062467e-02,\n",
       "        5.96492831e-03,  1.47996610e-02, -1.68416668e-02,  2.19650846e-02,\n",
       "        1.68211889e-02, -3.72648844e-03, -3.98907177e-02,  6.10463321e-03,\n",
       "        1.51735321e-02,  4.46834937e-02,  1.55037284e-01, -2.70888843e-02,\n",
       "        2.22862884e-02,  1.24306688e-02,  1.64271542e-03,  9.05045569e-02,\n",
       "        1.68985166e-02, -2.11323127e-02,  1.27235847e-02,  3.50222178e-02,\n",
       "        7.14509329e-03,  1.02892797e-03, -5.70083363e-03, -1.13453260e-02,\n",
       "        2.37459168e-02, -1.12610003e-02, -5.39831771e-03,  2.11189457e-04,\n",
       "       -3.48764146e-03,  3.80352139e-02, -2.43693199e-02,  2.57461611e-02,\n",
       "        2.36223731e-02,  1.59272309e-02,  5.56101929e-03, -1.48187121e-02,\n",
       "        9.85601638e-03, -1.23874738e-03, -1.11290105e-01, -6.88353227e-03,\n",
       "        1.25061553e-02, -4.70646583e-02,  4.06233082e-03, -1.03913888e-03,\n",
       "        2.79737804e-02,  7.77013134e-03, -3.68882231e-02, -5.31188026e-03,\n",
       "       -2.31079501e-03,  1.09736323e-02,  9.61849000e-03,  3.24840359e-02,\n",
       "       -1.41370492e-02, -9.45359748e-03, -7.22365174e-03, -2.80498900e-02,\n",
       "        1.85424183e-02,  2.69283801e-02, -9.29159485e-03,  1.77413560e-02,\n",
       "        2.43738405e-02,  2.78842300e-02,  8.11954029e-04,  5.36881760e-02,\n",
       "        7.80077428e-02, -9.06403270e-03, -1.39419790e-02, -4.08479432e-03,\n",
       "        6.97589591e-02,  1.67863574e-02, -2.97253504e-02, -3.33672091e-02,\n",
       "        2.84227617e-02,  1.31659657e-01, -4.06825822e-03, -1.64996386e-02,\n",
       "       -8.68956652e-03, -1.73855387e-02, -3.59993032e-03,  6.43999316e-03,\n",
       "        3.69681977e-02,  2.43741516e-02,  5.17745642e-03, -3.76323462e-02,\n",
       "        2.54263375e-02, -4.91385348e-03, -1.25271082e-02, -1.70386266e-02,\n",
       "        1.45678846e-02, -9.84764774e-04, -1.23311393e-02,  1.75559800e-02,\n",
       "       -1.62460618e-02, -1.69008896e-02,  1.77224237e-03,  5.46954805e-03,\n",
       "       -2.39657913e-03, -3.13786790e-02, -3.83012146e-02,  1.22565618e-02,\n",
       "        1.16034523e-02,  3.08811129e-03,  2.23686658e-02,  2.34462097e-02,\n",
       "       -3.39988433e-02, -2.78050633e-04,  2.80425698e-02,  5.73141035e-03,\n",
       "        1.03941327e-03, -6.55170232e-02,  3.97500172e-02, -2.58595552e-02,\n",
       "       -1.22736674e-02, -5.41958865e-03,  4.89056446e-02,  3.38139348e-02,\n",
       "       -1.15344152e-01, -2.63433903e-02,  2.11383272e-02, -9.84973013e-02,\n",
       "       -7.82056898e-03, -2.27626506e-02, -5.15239593e-03,  4.43675555e-02,\n",
       "        2.82536037e-02, -1.17219714e-02,  8.19497276e-04, -4.62664815e-04,\n",
       "        4.42170724e-02,  5.42959664e-03,  2.95305196e-02,  2.15595812e-02,\n",
       "        9.49520338e-03, -2.12128478e-04,  1.11191077e-02, -2.78283022e-02,\n",
       "        1.42085552e-02, -1.28372926e-02, -2.06405874e-02, -3.48764546e-02,\n",
       "       -1.64836813e-02,  6.70426637e-02, -4.48754383e-03, -2.49451008e-02,\n",
       "        1.42650108e-03,  2.71665026e-02, -3.94086875e-02, -3.39386798e-02,\n",
       "       -2.44044308e-02,  2.09329315e-02, -5.80144525e-02,  3.85063770e-03,\n",
       "        4.80583217e-03, -8.58306140e-03, -3.13905366e-02, -2.88756602e-02,\n",
       "        2.12756526e-02, -1.74006596e-02, -1.60197001e-02, -1.66589860e-02,\n",
       "        3.02532502e-02, -1.44790923e-02,  6.44850209e-02,  1.48820784e-02,\n",
       "       -2.19593081e-03, -4.37567793e-02, -6.17632642e-03,  3.95839382e-03,\n",
       "        1.99811347e-02,  2.50921026e-03,  1.25046307e-02,  2.50378922e-02,\n",
       "       -4.43046167e-02, -3.68239768e-02,  3.24406922e-02, -8.70592520e-02,\n",
       "        9.08842497e-03,  3.11855506e-03, -2.57601794e-02,  3.84728201e-02,\n",
       "       -1.91779330e-01, -4.97966493e-03,  5.74057130e-03, -9.90189612e-03,\n",
       "        6.75746659e-03,  5.57417609e-03,  6.83098624e-05, -5.14990017e-02,\n",
       "       -4.06275392e-02, -2.23675463e-02, -7.75488652e-03, -2.60081738e-02,\n",
       "       -1.55467894e-02,  2.07133591e-03, -2.53826939e-02,  1.94240548e-02,\n",
       "        1.22234970e-02,  9.58946242e-04,  2.02780943e-02,  2.54949625e-03,\n",
       "       -2.25603916e-02, -2.59977225e-02, -1.34318266e-02,  1.09355198e-02,\n",
       "        1.74472369e-02,  2.29098760e-02,  1.45834044e-03,  1.67395622e-02,\n",
       "       -1.08240907e-04, -6.17996678e-02,  1.92870237e-02, -6.20132759e-02,\n",
       "       -2.11894996e-02, -3.04211080e-02, -2.39437241e-02, -4.65150028e-02,\n",
       "        1.62337646e-02,  3.46834585e-02,  2.13193297e-02, -5.32133877e-03,\n",
       "       -2.71375030e-02, -1.34785157e-02,  1.91361811e-02,  1.83589384e-02,\n",
       "       -2.85263173e-03, -2.66054887e-02, -5.45985885e-02, -1.13354046e-02,\n",
       "       -2.72982824e-03, -1.24857230e-02, -1.48085682e-02, -8.30533635e-03,\n",
       "       -2.02974882e-02, -3.39525342e-02, -1.75375342e-02,  2.90781688e-02,\n",
       "       -1.82223711e-02,  3.67235579e-02, -1.33896545e-02, -1.68353040e-02,\n",
       "       -2.65365839e-03,  1.13128833e-02,  2.23267023e-02,  1.62804616e-03,\n",
       "        6.13442436e-02, -3.21637131e-02, -7.21672876e-03, -2.88662710e-03,\n",
       "        1.16281416e-02,  2.85797752e-02, -9.74975340e-03,  8.41126870e-03,\n",
       "        4.51191422e-03, -1.17541710e-02, -1.06992498e-02, -2.50955741e-03,\n",
       "        1.50735788e-02, -1.90670658e-02, -2.39616632e-03,  2.99938116e-02,\n",
       "        1.10327071e-02,  5.39995693e-02, -4.55867965e-03, -1.32367034e-02],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process based on file type\n",
    "if file_type == 'image':\n",
    "    try:\n",
    "        with Image.open(loading_file_path) as img:\n",
    "            img = img.convert('RGB')\n",
    "            content = image_to_caption(img, caption_processor, caption_model)\n",
    "            emb_vec = image_to_vector(img, emb_model, emb_processor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {loading_file_path}: {e}\")\n",
    "        \n",
    "elif file_type == 'text':\n",
    "    try:\n",
    "        with open(loading_file_path, 'r', encoding='utf-8') as f:\n",
    "            full_text = f.read()\n",
    "            content = summarize_text_file(summarizer, full_text)\n",
    "            emb_vec = text_to_vector(full_text, emb_model, emb_processor)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text file {file_path}: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Skipping unsupported file type: {file_path}\")\n",
    "\n",
    "display(\n",
    "    content,\n",
    "    emb_vec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def store_file(file_id: str, original_file_path: str, file_type: str):\n",
    "    # Create storage directory if it doesn't exist\n",
    "    os.makedirs(FILE_STORING_PATH, exist_ok=True)\n",
    "    \n",
    "    # Get the original file extension\n",
    "    original_path = Path(original_file_path)\n",
    "    file_extension = original_path.suffix.lower()\n",
    "    \n",
    "    # Handle files without extensions\n",
    "    if not file_extension:\n",
    "        if file_type == 'image':\n",
    "            file_extension = '.jpg'  # Default image format\n",
    "        else:\n",
    "            file_extension = '.txt'  # Default text format\n",
    "    \n",
    "    # Create storage path with file_id + original extension\n",
    "    storage_path = os.path.join(FILE_STORING_PATH, f\"{file_id}{file_extension}\")\n",
    "    \n",
    "    # Copy the file to storage\n",
    "    try:\n",
    "        if file_type == 'image':\n",
    "            # For images, we use the processed version to maintain RGB format\n",
    "            with Image.open(original_file_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img.save(storage_path)\n",
    "            print(f\"Stored image: {storage_path}\")\n",
    "        else:\n",
    "            # For text files, copy the original content\n",
    "            shutil.copy2(original_file_path, storage_path)\n",
    "            print(f\"Stored text: {storage_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error storing file {original_file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return storage_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "INDEX_FILE = os.path.join(VECTOR_DB_PATH, \"file_index.faiss\")\n",
    "METADATA_FILE = os.path.join(VECTOR_DB_PATH, \"index_metadata.json\")\n",
    "\n",
    "# Initialize global variables\n",
    "index = None\n",
    "metadata_list = []\n",
    "\n",
    "def load_or_create_vector_db():\n",
    "    global index, metadata_list\n",
    "    os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
    "    # Check if database exists\n",
    "    if os.path.exists(INDEX_FILE) and os.path.exists(METADATA_FILE):\n",
    "        print(\"Loading existing vector database...\")\n",
    "        try:\n",
    "            # Load FAISS index\n",
    "            index = faiss.read_index(INDEX_FILE)\n",
    "            \n",
    "            # Load metadata\n",
    "            with open(METADATA_FILE, 'r') as f:\n",
    "                metadata_list = json.load(f)\n",
    "                \n",
    "            print(f\"Loaded vector DB with {index.ntotal} entries\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector DB: {e}\")\n",
    "            create_new_vector_db()\n",
    "    else:\n",
    "        print(\"Creating new vector database...\")\n",
    "        create_new_vector_db()\n",
    "        \n",
    "    return index, metadata_list\n",
    "\n",
    "def create_new_vector_db():\n",
    "    \"\"\"Create a new empty vector database\"\"\"\n",
    "    global index, metadata_list\n",
    "    dimension = 512  # CLIP embedding dimension\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    metadata_list = []\n",
    "    save_vector_db()\n",
    "    print(f\"Created new vector DB with dimension {dimension}\")\n",
    "\n",
    "def save_vector_db():\n",
    "    \"\"\"Save the vector database to disk\"\"\"\n",
    "    try:\n",
    "        # Save FAISS index\n",
    "        faiss.write_index(index, INDEX_FILE)\n",
    "        \n",
    "        # Save metadata\n",
    "        with open(METADATA_FILE, 'w') as f:\n",
    "            json.dump(metadata_list, f, indent=2)\n",
    "            \n",
    "        print(f\"Saved vector DB with {index.ntotal} entries\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving vector DB: {e}\")\n",
    "\n",
    "def store_embedding(embedding: np.ndarray, meta_data: dict):\n",
    "    \"\"\"\n",
    "    Store embedding and metadata in vector database\n",
    "    \n",
    "    Args:\n",
    "        embedding: Embedding vector (1D numpy array)\n",
    "        meta_data: Metadata dictionary\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    # Ensure embedding is in correct format\n",
    "    if len(embedding.shape) == 1:\n",
    "        embedding = embedding.reshape(1, -1)\n",
    "    \n",
    "    # Add to index\n",
    "    index.add(embedding.astype('float32'))\n",
    "    \n",
    "    # Add to metadata\n",
    "    metadata_list.append(meta_data)\n",
    "    \n",
    "    # Save to disk\n",
    "    save_vector_db()\n",
    "    \n",
    "    print(f\"Stored embedding for: {meta_data['file_name']}\")\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Update the store_Vdb function\n",
    "def store_Vdb(embedding: np.ndarray, meta_data: dict):\n",
    "    \"\"\"Store in vector database (actual implementation)\"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    # Load DB if not already loaded\n",
    "    if index is None:\n",
    "        index, metadata_list = load_or_create_vector_db()\n",
    "    \n",
    "    # Store the embedding\n",
    "    store_embedding(embedding, meta_data)\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def retrieve_all_embeddings():\n",
    "    \"\"\"\n",
    "    Retrieve all stored embeddings and metadata\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (embeddings, metadata_list)\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    if index.ntotal == 0:\n",
    "        return np.array([]), []\n",
    "    \n",
    "    # Retrieve all embeddings\n",
    "    all_embeddings = index.reconstruct_n(0, index.ntotal)\n",
    "    \n",
    "    return all_embeddings, metadata_list\n",
    "\n",
    "def search_similar(query_embedding: np.ndarray, k: int = 5):\n",
    "    \"\"\"\n",
    "    Search for similar vectors in the database\n",
    "    \n",
    "    Args:\n",
    "        query_embedding: Embedding vector to compare against\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Metadata of top k matches\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    if index.ntotal == 0:\n",
    "        return []\n",
    "    \n",
    "    # Prepare query vector\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding.reshape(1, -1)\n",
    "    \n",
    "    # Perform search\n",
    "    distances, indices = index.search(query_embedding.astype('float32'), k)\n",
    "    \n",
    "    # Get metadata for results\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        if i >= 0:  # FAISS returns -1 for invalid indices\n",
    "            results.append(metadata_list[i])\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# New function for searching files\n",
    "def search_files(query: str, k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search files based on text query\n",
    "    \n",
    "    Args:\n",
    "        query: Text query to search for\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of metadata dictionaries for matching files\n",
    "    \"\"\"\n",
    "    # Load models and DB\n",
    "    _, _, _, emb_processor, emb_model = load_models()\n",
    "    if index is None:\n",
    "        index, metadata_list = load_or_create_vector_db()\n",
    "    \n",
    "    # Convert query to embedding\n",
    "    query_embedding = text_to_vector(query, emb_model, emb_processor)\n",
    "    \n",
    "    # Search vector DB\n",
    "    results = search_similar(query_embedding, k)\n",
    "    \n",
    "    # Format results\n",
    "    for result in results:\n",
    "        result['stored_file'] = os.path.join(\n",
    "            FILE_STORING_PATH, \n",
    "            f\"{result['file_id']}{Path(result['file_path']).suffix}\"\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored image: ../files_DB/sea_54380609.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../files_DB/sea_54380609.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: storing file in DB + file_id\n",
    "storage_path = store_file(file_id, original_file_path =loading_file_path , file_type =file_type)\n",
    "storage_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector database...\n",
      "Loaded vector DB with 1 entries\n",
      "Saved vector DB with 2 entries\n",
      "Stored embedding for: sea.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: store: text_embedding,metadata\n",
    "metadata = {\n",
    "    'file_id': file_id,\n",
    "    'file_name': file_name,\n",
    "    'file_path': str(Path(file_path).resolve()),\n",
    "    'file_type': file_type,\n",
    "    'content': content,\n",
    "    'storage_path' : storage_path\n",
    "}\n",
    "\n",
    "load_or_create_vector_db()\n",
    "store_Vdb(emb_vec, metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "\n",
    "# Get the directory of the current script\n",
    "LOCAL_RETRIEVAL_DIR =   \"../models/embedding\"\n",
    "VECTOR_DB_PATH =   \"../vectorDB\"\n",
    "INDEX_FILE =  \"file_index.faiss\"\n",
    "METADATA_FILE = \"index_metadata.json\"\n",
    "\n",
    "\n",
    "index = None\n",
    "metadata_list = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def load_models():\n",
    "    emb_processor = CLIPProcessor.from_pretrained(LOCAL_RETRIEVAL_DIR)\n",
    "    emb_model     = CLIPModel.from_pretrained(LOCAL_RETRIEVAL_DIR).to(device)\n",
    "    return emb_processor, emb_model\n",
    "\n",
    "def text_to_vector(text: str, emb_model, emb_processor) -> np.ndarray:\n",
    "    inputs = emb_processor(text=text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = emb_model.get_text_features(**inputs)\n",
    "    # Normalize to unit vector (L2 norm)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features.cpu().numpy().squeeze()\n",
    "\n",
    "def load_or_create_vector_db():\n",
    "    global index, metadata_list\n",
    "    os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
    "    # Check if database exists\n",
    "    if os.path.exists(INDEX_FILE) and os.path.exists(METADATA_FILE):\n",
    "        print(\"Loading existing vector database...\")\n",
    "        try:\n",
    "            # Load FAISS index\n",
    "            index = faiss.read_index(INDEX_FILE)\n",
    "            \n",
    "            # Load metadata\n",
    "            with open(METADATA_FILE, 'r') as f:\n",
    "                metadata_list = json.load(f)\n",
    "                \n",
    "            print(f\"Loaded vector DB with {index.ntotal} entries\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector DB: {e}\")\n",
    "            create_new_vector_db()\n",
    "    else:\n",
    "        print(\"Creating new vector database...\")\n",
    "        create_new_vector_db()\n",
    "        \n",
    "    return index, metadata_list\n",
    "def create_new_vector_db():\n",
    "    \"\"\"Create a new empty vector database\"\"\"\n",
    "    global index, metadata_list\n",
    "    dimension = 512  # CLIP embedding dimension\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    metadata_list = []\n",
    "    save_vector_db()\n",
    "    print(f\"Created new vector DB with dimension {dimension}\")\n",
    "\n",
    "def save_vector_db():\n",
    "    \"\"\"Save the vector database to disk\"\"\"\n",
    "    try:\n",
    "        # Save FAISS index\n",
    "        faiss.write_index(index, INDEX_FILE)\n",
    "        \n",
    "        # Save metadata\n",
    "        with open(METADATA_FILE, 'w') as f:\n",
    "            json.dump(metadata_list, f, indent=2)\n",
    "            \n",
    "        print(f\"Saved vector DB with {index.ntotal} entries\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving vector DB: {e}\")\n",
    "\n",
    "def search_similar(query_embedding: np.ndarray, k: int = 5):\n",
    "    \"\"\"\n",
    "    Search for similar vectors in the database\n",
    "    \n",
    "    Args:\n",
    "        query_embedding: Embedding vector to compare against\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Metadata of top k matches\n",
    "    \"\"\"\n",
    "    global index, metadata_list\n",
    "    \n",
    "    if index.ntotal == 0:\n",
    "        return []\n",
    "    \n",
    "    # Prepare query vector\n",
    "    if len(query_embedding.shape) == 1:\n",
    "        query_embedding = query_embedding.reshape(1, -1)\n",
    "    \n",
    "    # Perform search\n",
    "    distances, indices = index.search(query_embedding.astype('float32'), k)\n",
    "    \n",
    "    # Get metadata for results\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        if i >= 0:  # FAISS returns -1 for invalid indices\n",
    "            results.append(metadata_list[i]['file_path'])\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def semantic_search_engine(search_query: str):\n",
    "    load_or_create_vector_db()\n",
    "    emb_processor, emb_model = load_models()\n",
    "    search_emb = text_to_vector(search_query, emb_model, emb_processor)\n",
    "    relevant_files_paths = search_similar(search_emb)\n",
    "    return relevant_files_paths\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector database...\n",
      "Loaded vector DB with 0 entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query = \"sea with blue sky\"\n",
    "semantic_search_engine(search_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
